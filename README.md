# DocuReadAI
**DocuReadAI** is an intelligent document understanding assistant built using LangChain, HuggingFace embeddings, Chroma vector store, and IBM Watsonx large language models. It enables seamless extraction of insights from PDF documents through natural language queries.

---

## ğŸ” Overview
This assistant allows users to upload any PDF, automatically extract and embed its content, and then query the document using natural language. Answers are generated based on relevant sections retrieved from a local vector database, enabling fast and contextually accurate responses.

---

## âš™ï¸ Tech Stack
- ğŸ§  **LangChain** â€“ Modular orchestration of document workflows
- ğŸ’¬ **HuggingFace Transformers** â€“ Embedding model (`all-MiniLM-L6-v2`)
- ğŸ§± **Chroma** â€“ Lightweight local vector database
- â˜ï¸ **IBM Watsonx** â€“ LLM inference via foundation models
- ğŸ›ï¸ **Gradio** â€“ User-friendly browser interface

---

## ğŸš€ Features
- Upload and process PDF files
- Split and embed document content
- Store semantic vectors locally
- Retrieve contextually relevant chunks
- Ask questions and get instant, accurate answers
- Runs entirely on your machine with secure Watsonx API integration

---

## ğŸ”§Setup Instructions
### 1. Clone the repo
```bash
git clone https://github.com/MrCoss/DocuReadAI.git
cd DocuReadAI
````

### 2. Prepare the `.env` file
Create a `.env` file in the root directory with your IBM Cloud Watsonx credentials:
```ini
WATSONX_API_KEY=your_api_key_here
WATSONX_PROJECT_ID=your_project_id_here
WATSONX_URL=https://eu-gb.ml.cloud.ibm.com
MODEL_ID=google/flan-ul2
```

> Keep your `.env` file private â€” do not commit it to version control.
### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Launch the app
```bash
python main.py
```
---
## Interface
Once launched, a Gradio UI opens in your browser:

* Upload your PDF
* Ask a question like:
  *â€œWhat is this document about?â€*
* Get an answer powered by retrieval-augmented generation (RAG)

## ğŸ–¼ï¸ Screenshots
<img width="1911" height="862" alt="qa_bot" src="https://github.com/user-attachments/assets/7cd4a4e8-c079-404a-8d16-2b88882d1d1f" />
<img width="547" height="227" alt="load_documents" src="https://github.com/user-attachments/assets/41d778a5-6020-4f67-a995-79cebb0e8b5c" />
<img width="828" height="220" alt="split_text" src="https://github.com/user-attachments/assets/64211367-710d-4731-94fa-225967ce021a" />
<img width="927" height="212" alt="embed_documents" src="https://github.com/user-attachments/assets/974a4a8c-1528-4413-9228-ab0c28a49d12" />
<img width="582" height="191" alt="vector_db" src="https://github.com/user-attachments/assets/6b87bc49-5ff8-4dca-a1ab-b72b892b1859" />
<img width="635" height="210" alt="retriver" src="https://github.com/user-attachments/assets/d07a6e42-5fd3-46eb-8a6e-c37a5153d5c4" />
<img width="4560" height="1113" alt="Blank diagram" src="https://github.com/user-attachments/assets/7b73b50f-7172-4a71-8c75-e6efbdb2c617" />

---

## ğŸ“ Project Structure
```bash
.
â”œâ”€â”€ main.py             # Full RAG pipeline (Tasks 1â€“6)
â”œâ”€â”€ .env                # Watsonx credentials (excluded from Git)
â”œâ”€â”€ requirements.txt    # Python packages
â”œâ”€â”€ .gitignore          # Ignored files/folders
â””â”€â”€ README.md           # Project documentation

## Example Query
> **PDF:** Any research paper, legal document, or report
> **Question:** `"What are the key findings in this paper?"`
> **Answer:** Semantic summary generated by Watsonx LLM, grounded in embedded context from Chroma.

##
Costas Pinto
GitHub: [MrCoss](https://github.com/MrCoss)


